# Data analysis as a life saver
This repository consits of multiple folders:
* Spark
  * data_prep
  * model_train
  * HTML
    * data_prep.html
    * model_train.html
* Jupyter
  * model_train.ipynb
  * requirements.txt
* presentation.pdf
* executive_summary.pdf

In Spark folder, there is the code we used for training and evaluating our model. In the latter, there is runnable jupyter notebook with small data subsample.
Data preprocessing is not in the jupyter part as we needed to use distributed computing for efficiency. In spark file, there are also exported html versions of runned notebooks. 
There is also an Executive summary, where there is some reasoning behind the model selection as well as pdf export of our presentation. 


